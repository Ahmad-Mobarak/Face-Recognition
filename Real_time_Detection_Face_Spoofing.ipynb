{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4fNSQOIeKMU6"
   },
   "source": [
    "# Real-time Detecting in Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "g7I7lX4k9o2S",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "executionInfo": {
     "status": "error",
     "timestamp": 1737155010046,
     "user_tz": -120,
     "elapsed": 337,
     "user": {
      "displayName": "Mohamed Mekky",
      "userId": "14274963257959360910"
     }
    },
    "outputId": "13b63c24-c7c4-4895-da62-8194f4678515"
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "(unicode error) 'unicodeescape' codec can't decode bytes in position 3-4: truncated \\UXXXXXXXX escape (<ipython-input-5-0df75e32e121>, line 14)",
     "traceback": [
      "\u001B[0;36m  File \u001B[0;32m\"<ipython-input-5-0df75e32e121>\"\u001B[0;36m, line \u001B[0;32m14\u001B[0m\n\u001B[0;31m    model = load_model('\"C:\\Users\\dell\\Downloads\\MobileNetFaceSpoof (4).h5\"', custom_objects={})\u001B[0m\n\u001B[0m                                                                            ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 3-4: truncated \\UXXXXXXXX escape\n"
     ]
    }
   ],
   "source": [
    "from google.colab.patches import cv2_imshow\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.models import load_model\n",
    "import IPython.display as display\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode\n",
    "import PIL.Image\n",
    "import io\n",
    "\n",
    "model = load_model('\"C:\\Users\\dell\\Downloads\\MobileNetFaceSpoof (4).h5\"', custom_objects={})\n",
    "emotion_labels_2 = [\"live\", \"spoof\"]\n",
    "\n",
    "# JavaScript function to capture image from webcam\n",
    "def take_photo(filename='photo.jpg', quality=0.8):\n",
    "    js = f\"\"\"\n",
    "    async function takePhoto() {{\n",
    "        const div = document.createElement('div');\n",
    "        document.body.appendChild(div);\n",
    "        const video = document.createElement('video');\n",
    "        video.style.display = 'block';\n",
    "        document.body.appendChild(video);\n",
    "\n",
    "        const stream = await navigator.mediaDevices.getUserMedia({{video: true}});\n",
    "        video.srcObject = stream;\n",
    "        await new Promise((resolve) => (video.onloadedmetadata = resolve));\n",
    "        video.play();\n",
    "\n",
    "        await new Promise((resolve) => setTimeout(resolve, 1000));\n",
    "\n",
    "        const canvas = document.createElement('canvas');\n",
    "        canvas.width = video.videoWidth;\n",
    "        canvas.height = video.videoHeight;\n",
    "        canvas.getContext('2d').drawImage(video, 0, 0);\n",
    "\n",
    "        stream.getTracks().forEach(track => track.stop());\n",
    "        video.remove();\n",
    "\n",
    "        const dataURL = canvas.toDataURL('image/jpeg', {quality});\n",
    "        return dataURL;\n",
    "    }}\n",
    "    takePhoto();\n",
    "    \"\"\"\n",
    "    data = eval_js(js)\n",
    "    binary = b64decode(data.split(',')[1])\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(binary)\n",
    "    return filename\n",
    "\n",
    "image_path = take_photo()\n",
    "\n",
    "frame = cv2.imread(image_path)\n",
    "\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    face_roi = frame[y:y+h, x:x+w]\n",
    "    face_roi = cv2.resize(face_roi, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "    face_rgb = cv2.cvtColor(face_roi, cv2.COLOR_BGR2RGB)\n",
    "    face_array = img_to_array(face_rgb)\n",
    "    face_array = np.expand_dims(face_array, axis=0)\n",
    "    face_array = preprocess_input(face_array)\n",
    "\n",
    "    prediction = model.predict(face_array)[0]\n",
    "    if prediction < 0.7:\n",
    "        label = 'Real'\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "    else:\n",
    "        label = 'Spoof'\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "        cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX,0.9, (0, 0, 255), 2)\n",
    "\n",
    "    #label = emotion_labels_2[emotion_index]\n",
    "    print(prediction,label)\n",
    "\n",
    "cv2_imshow(frame)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEhQFyq2Kf81"
   },
   "source": [
    "# Detecting From Video"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TcTnv1nhGF4X",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1737154983346,
     "user_tz": -120,
     "elapsed": 27314,
     "user": {
      "displayName": "Mohamed Mekky",
      "userId": "14274963257959360910"
     }
    },
    "outputId": "15ba349e-aa6a-40ab-b41f-243524f9b027",
    "ExecuteTime": {
     "end_time": "2025-01-18T01:20:23.638746Z",
     "start_time": "2025-01-18T01:20:23.611466Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcolab\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m drive\n\u001B[0;32m      2\u001B[0m drive\u001B[38;5;241m.\u001B[39mmount(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/content/drive\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'google.colab'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "output_embedded_package_id": "1WucR2Gde-RPa4Ux0slHAFzMhnF7ULG2C"
    },
    "id": "Anxby7apNIhr",
    "outputId": "b1b43e8d-9a9d-434a-bf4b-1e8fb2f2ad9b",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1737149128540,
     "user_tz": -120,
     "elapsed": 115544,
     "user": {
      "displayName": "shehab ziada",
      "userId": "00990799770551983311"
     }
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "Output hidden; open in https://colab.research.google.com to view."
     },
     "metadata": {}
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.models import load_model\n",
    "from google.colab.patches import cv2_imshow\n",
    "\n",
    "model = load_model('/content/drive/MyDrive/Face_anti_spoof/MobileNetFaceSpoof.h5', custom_objects={})\n",
    "emotion_labels_2 = [\"live\", \"spoof\"]\n",
    "\n",
    "video_path = 'WIN_20250117_17_48_20_Pro.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('output.mp4', fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_roi = frame[y:y+h, x:x+w]\n",
    "        face_roi = cv2.resize(face_roi, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "        face_rgb = cv2.cvtColor(face_roi, cv2.COLOR_BGR2RGB)\n",
    "        face_array = img_to_array(face_rgb)\n",
    "        face_array = np.expand_dims(face_array, axis=0)\n",
    "        face_array = preprocess_input(face_array)\n",
    "\n",
    "        prediction = model.predict(face_array)[0]\n",
    "        if prediction < 0.7:\n",
    "            label = 'Real'\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "        else:\n",
    "            label = 'Spoof'\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "            cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX,0.9, (0, 0, 255), 2)\n",
    "\n",
    "    #label = emotion_labels_2[emotion_index]\n",
    "    print(prediction,label)\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "import base64\n",
    "\n",
    "def show_video(video_path):\n",
    "    mp4 = open(video_path, 'rb').read()\n",
    "    data_url = \"data:video/mp4;base64,\" + base64.b64encode(mp4).decode()\n",
    "    display(HTML(f'<video width=\"640\" height=\"480\" controls><source src=\"{data_url}\" type=\"video/mp4\"></video>'))\n",
    "\n",
    "show_video('output.mp4')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_tkJ-a5KnE-"
   },
   "source": [
    "# Detecting Real-time From Local jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hbapIwy-HwCn",
    "outputId": "e743b21d-34cc-4ce5-978f-a42a9a0b2768"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('MobileNetFaceSpoof.h5', custom_objects={})\n",
    "emotion_labels_2 = [\"live\", \"spoof\"]\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face_roi = frame[y:y+h, x:x+w]\n",
    "        face_roi = cv2.resize(face_roi, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "        face_rgb = cv2.cvtColor(face_roi, cv2.COLOR_BGR2RGB)\n",
    "        face_array = img_to_array(face_rgb)\n",
    "        face_array = np.expand_dims(face_array, axis=0)\n",
    "        face_array = preprocess_input(face_array)\n",
    "\n",
    "        prediction = model.predict(face_array)[0]\n",
    "        if prediction < 0.7:\n",
    "            label = 'Real'\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "        else:\n",
    "            label = 'Spoof'\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "            cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX,0.9, (0, 0, 255), 2)\n",
    "\n",
    "    cv2.imshow('Real-Time Face Spoof Detection', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "COCQ9hlaLt-O"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
